# app.py
import streamlit as st
import os
import time
import json
from datetime import datetime
from fpdf import FPDF
from utils.pdf_processor import PDFProcessor
from utils.nlp_analyzer import NLPAnalyzer

def create_summary_pdf(summary, filename):
    """Create a proper PDF file with the summary"""
    pdf = FPDF()
    pdf.add_page()
    
    # Set font for title (use Arial which supports basic characters)
    pdf.set_font("Arial", 'B', 16)
    pdf.cell(200, 10, txt="QuickRead AI - Document Summary", ln=True, align='C')
    pdf.ln(5)
    
    # File info
    pdf.set_font("Arial", 'I', 10)
    pdf.cell(200, 10, txt=f"Original File: {filename}", ln=True)
    pdf.cell(200, 10, txt=f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", ln=True)
    pdf.ln(10)
    
    # Add a line
    pdf.set_draw_color(0, 0, 0)
    pdf.line(10, pdf.get_y(), 200, pdf.get_y())
    pdf.ln(10)
    
    # Summary title
    pdf.set_font("Arial", 'B', 14)
    pdf.cell(200, 10, txt="Document Summary:", ln=True)
    pdf.ln(5)
    
    # Summary content - remove any special characters that might cause issues
    pdf.set_font("Arial", size=12)
    
    # Clean the summary text - replace bullets with dashes
    clean_summary = summary.replace('â€¢', '-')
    
    # Split summary into lines that fit the page width
    summary_lines = []
    words = clean_summary.split()
    line = ""
    
    for word in words:
        test_line = line + word + " "
        if pdf.get_string_width(test_line) < 180:  # 180mm width
            line = test_line
        else:
            summary_lines.append(line)
            line = word + " "
    if line:
        summary_lines.append(line)
    
    # Add each line to PDF
    for line in summary_lines:
        pdf.cell(200, 10, txt=line, ln=True)
    
    # Footer
    pdf.ln(20)
    pdf.set_font("Arial", 'I', 10)
    pdf.cell(200, 10, txt="Generated by QuickRead AI - Smart PDF Analysis Tool", ln=True, align='C')
    
    # Convert bytearray to bytes
    pdf_bytes = pdf.output()
    if isinstance(pdf_bytes, bytearray):
        pdf_bytes = bytes(pdf_bytes)
    
    return pdf_bytes

def main():
    # Page configuration
    st.set_page_config(
        page_title="QuickRead AI",
        page_icon="ðŸ“„",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Header
    st.title("QuickRead AI")
    st.markdown("**Instant PDF Analysis â€¢ Smart Summarization â€¢ Sentiment Detection**")
    
    # Initialize processors
    @st.cache_resource
    def load_processors():
        return PDFProcessor(), NLPAnalyzer()
    
    pdf_processor, nlp_analyzer = load_processors()
    
    # Sidebar
    with st.sidebar:
        st.header("Upload PDF")
        uploaded_file = st.file_uploader("Choose a PDF file", type="pdf")
        
        st.markdown("---")
        st.header("Analysis Options")
        show_summary = st.checkbox("Generate Summary", value=True)
        show_sentiment = st.checkbox("Sentiment Analysis", value=True)
        show_key_points = st.checkbox("Extract Key Points", value=True)
        show_stats = st.checkbox("Text Statistics", value=True)
        
        analyze_button = st.button("Analyze Document", type="primary")
    
    # Main content
    if uploaded_file is not None:
        st.success(f"File Ready: {uploaded_file.name}")
        
        if analyze_button:
            with st.spinner("AI is analyzing your document..."):
                try:
                    # Process PDF
                    text, page_count, extraction_info = pdf_processor.extract_text(uploaded_file)
                    
                    # Display extraction info
                    st.markdown("---")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Pages Extracted", page_count)
                    with col2:
                        st.metric("Extraction Method", extraction_info["method"])
                    with col3:
                        st.metric("Status", extraction_info["status"])
                    
                    # Clean text
                    cleaned_text = nlp_analyzer.clean_text(text)
                    
                    # Show text statistics
                    if show_stats:
                        with st.expander("Text Statistics", expanded=True):
                            stats = nlp_analyzer.get_text_stats(cleaned_text)
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Words", stats["word_count"])
                            with col2:
                                st.metric("Sentences", stats["sentence_count"])
                            with col3:
                                st.metric("Characters", stats["character_count"])
                            with col4:
                                st.metric("Avg Sentence Length", stats["avg_sentence_length"])
                    
                    # Show summary with improved algorithm
                    summary = ""
                    if show_summary:
                        with st.expander("Document Summary", expanded=True):
                            summary = nlp_analyzer.generate_summary(cleaned_text)
                            st.write(summary)
                    
                    # Show sentiment analysis
                    if show_sentiment:
                        with st.expander("Sentiment Analysis", expanded=True):
                            sentiment_data = nlp_analyzer.analyze_sentiment(cleaned_text)
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Sentiment", sentiment_data['label'])
                            with col2:
                                st.metric("Polarity", sentiment_data["polarity"])
                            with col3:
                                st.metric("Subjectivity", sentiment_data["subjectivity"])
                            with col4:
                                # Visual indicator
                                polarity = sentiment_data["polarity"]
                                if polarity > 0.1:
                                    st.success("Positive Tone")
                                elif polarity < -0.1:
                                    st.error("Negative Tone")
                                else:
                                    st.info("Neutral Tone")
                    
                    # Show key points
                    if show_key_points:
                        with st.expander("Key Points", expanded=True):
                            key_points = nlp_analyzer.extract_key_points(cleaned_text)
                            for i, point in enumerate(key_points, 1):
                                st.write(f"{i}. {point}")
                    
                    # Show raw text preview
                    with st.expander("Extracted Text (Preview)", expanded=False):
                        st.text_area("Full extracted text", cleaned_text[:2000] + ("..." if len(cleaned_text) > 2000 else ""), height=200)
                    
                    # Download section - PROPER PDF GENERATION
                    if show_summary and summary:
                        st.markdown("---")
                        st.header("Download Summary")
                        
                        # Create proper PDF
                        pdf_data = create_summary_pdf(summary, uploaded_file.name)
                        
                        # Download button for PDF summary
                        st.download_button(
                            label="Download Summary as PDF",
                            data=pdf_data,
                            file_name=f"summary_{uploaded_file.name.split('.')[0]}.pdf",
                            mime="application/pdf",
                            help="Download only the document summary as a PDF file"
                        )
                    
                    st.success("Analysis complete!")
                    
                except Exception as e:
                    st.error(f"Error analyzing PDF: {str(e)}")
                    st.info("Tip: Make sure your PDF contains selectable text (not scanned images)")
        else:
            st.warning("Click 'Analyze Document' to start analysis")
    
    else:
        # Welcome message when no file uploaded
        st.markdown("---")
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("Welcome to QuickRead AI!")
            st.markdown("""
            **Upload a PDF document to get:**
            
            - **Smart Summarization** - AI-powered document summaries
            - **Sentiment Analysis** - Understand the emotional tone
            - **Key Points Extraction** - Main ideas at a glance
            - **Text Statistics** - Word count, sentence analysis
            - **PDF Export** - Download summary as PDF
            - **Instant Results** - No complex setup required
            
            **How to use:**
            1. Upload a PDF file using the sidebar
            2. Select your analysis options
            3. Click 'Analyze Document'
            4. Get instant insights and download PDF summary!
            """)
        
        with col2:
            st.image("https://cdn-icons-png.flaticon.com/512/337/337946.png", 
                    width=150, caption="QuickRead AI")
        
        st.markdown("---")
        st.info("**Note:** This tool works best with PDFs that contain selectable text. Scanned image PDFs may not work properly.")

if __name__ == "__main__":
    main()